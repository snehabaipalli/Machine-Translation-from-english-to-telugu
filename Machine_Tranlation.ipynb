{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW4Pg5X1nC8D",
        "outputId": "e82cfccb-e095-49ee-f9b1-242a21aa1e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW2bbZlOndb9"
      },
      "outputs": [],
      "source": [
        "project_path=\"/content/drive/My Drive/Machine_Translation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-40tXPpgNsht"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTQO2rcTQBuj"
      },
      "outputs": [],
      "source": [
        "# read phrases from english_telugu_data.txt file\n",
        "english_sentences = []\n",
        "telugu_sentences = []\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"en-te_parallel_corpus.csv\")\n",
        "english_sentences=df[\"en_sent\"].iloc[0:500]\n",
        "telugu_sentences=df[\"te_sent\"].iloc[0:500]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tm4OPXyFQeG3",
        "outputId": "4d8a8472-0fa6-45f9-ba29-052e137c2eeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     english_sentences  \\\n",
              "0    Three members of a family were killed in the i...   \n",
              "1    In Monaco-Ville, street signs are printed in b...   \n",
              "2    The same has been confirmed in a report carrie...   \n",
              "3    In this state they can easily survive one year...   \n",
              "4    Annual International Yoga Day is a modern cele...   \n",
              "..                                                 ...   \n",
              "495  Each State delegation in the Congress casts on...   \n",
              "496  The NTR biopic is being made into a two-part f...   \n",
              "497  The court had also served notice on the CBI im...   \n",
              "498  North Korea has carried out repeated nuclear a...   \n",
              "499  Kohli has played 12 ODIs against Pakistan in w...   \n",
              "\n",
              "                                      telugu_sentences  \n",
              "0    ఓకే కుటుంబానికి చెందిన ముగ్గురు మృతిచెందటంతో ఈ...  \n",
              "1    మొనాకో-విల్లెలో, ఫ్రెంచ్, మోనెగస్క్యూ రెండింటి...  \n",
              "2           ప్రముఖ బీబీసీ నివేదిక ఇదే విషయం పేర్కొంది.  \n",
              "3    సంవత్సరానికి అదనంగా ఒక రోజునో లేక ఒక నెలనో చేర...  \n",
              "4    ఇలా అంతర్జాతీయ యోగ దినోత్సవం భారతీయ సంస్కార ప్...  \n",
              "..                                                 ...  \n",
              "495            ప్రతి రాష్ట్రం కాంగ్రెస్లో ఓటు ఉంటుంది.  \n",
              "496  ఎన్టీఆర్ బయోపిక్ రెండు భాగాలుగా రూపొందుతున్న స...  \n",
              "497  ఈ కేసులో సిబిఐకి కూడా అప్పుడు కోర్టు నోటీసులు ...  \n",
              "498  ఉత్తర కొరియా ఇటీవల పదేపదే మిసైల్, అణుపరీక్షలు ...  \n",
              "499  12 మ్యాచ్‌ల్లో విరాట్ కోహ్లీ 45.90 యావరేజితో 4...  \n",
              "\n",
              "[500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-177f5430-0071-455b-a746-8b9e3d6cbf53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentences</th>\n",
              "      <th>telugu_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Three members of a family were killed in the i...</td>\n",
              "      <td>ఓకే కుటుంబానికి చెందిన ముగ్గురు మృతిచెందటంతో ఈ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In Monaco-Ville, street signs are printed in b...</td>\n",
              "      <td>మొనాకో-విల్లెలో, ఫ్రెంచ్, మోనెగస్క్యూ రెండింటి...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The same has been confirmed in a report carrie...</td>\n",
              "      <td>ప్రముఖ బీబీసీ నివేదిక ఇదే విషయం పేర్కొంది.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In this state they can easily survive one year...</td>\n",
              "      <td>సంవత్సరానికి అదనంగా ఒక రోజునో లేక ఒక నెలనో చేర...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Annual International Yoga Day is a modern cele...</td>\n",
              "      <td>ఇలా అంతర్జాతీయ యోగ దినోత్సవం భారతీయ సంస్కార ప్...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>Each State delegation in the Congress casts on...</td>\n",
              "      <td>ప్రతి రాష్ట్రం కాంగ్రెస్లో ఓటు ఉంటుంది.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>The NTR biopic is being made into a two-part f...</td>\n",
              "      <td>ఎన్టీఆర్ బయోపిక్ రెండు భాగాలుగా రూపొందుతున్న స...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>The court had also served notice on the CBI im...</td>\n",
              "      <td>ఈ కేసులో సిబిఐకి కూడా అప్పుడు కోర్టు నోటీసులు ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>North Korea has carried out repeated nuclear a...</td>\n",
              "      <td>ఉత్తర కొరియా ఇటీవల పదేపదే మిసైల్, అణుపరీక్షలు ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Kohli has played 12 ODIs against Pakistan in w...</td>\n",
              "      <td>12 మ్యాచ్‌ల్లో విరాట్ కోహ్లీ 45.90 యావరేజితో 4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-177f5430-0071-455b-a746-8b9e3d6cbf53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-177f5430-0071-455b-a746-8b9e3d6cbf53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-177f5430-0071-455b-a746-8b9e3d6cbf53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data = pd.DataFrame({\"english_sentences\":english_sentences,\"telugu_sentences\":telugu_sentences})\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI0id65sQkgK"
      },
      "outputs": [],
      "source": [
        "# clean english sentances\n",
        "def clean_eng(text):\n",
        "    # Lowercase all characters\n",
        "    text = text.lower()\n",
        "    # Remove quotes\n",
        "    text = re.sub(\"'\", '', text)\n",
        "    # Remove all the special characters\n",
        "    exclude = set(string.punctuation) # Set of all special characters\n",
        "    text = ''.join([c for c in text if c not in exclude])\n",
        "    # Remove all numbers from text\n",
        "    remove_digits = str.maketrans('', '', digits)\n",
        "    text = text.translate(remove_digits)\n",
        "    # Remove extra spaces\n",
        "    text= text.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UjSVXXQeyhw"
      },
      "outputs": [],
      "source": [
        "# clean telugu sentances\n",
        "def clean_tel(text):\n",
        "    # Lowercase all characters\n",
        "    text = text.lower()\n",
        "    # Remove quotes\n",
        "    text = re.sub(\"'\", '', text)\n",
        "    # Remove all the special characters\n",
        "    exclude = set(string.punctuation) # Set of all special characters\n",
        "    text = ''.join([c for c in text if c not in exclude])\n",
        "    # Remove all numbers from text\n",
        "    remove_digits = str.maketrans('', '', digits)\n",
        "    text = text.translate(remove_digits)\n",
        "    # Remove Telugu numbers from text\n",
        "    text = re.sub(\"[౦౧౨౩౪౫౬౭౮౯]\", '', text)\n",
        "    # Remove extra spaces\n",
        "    text= text.strip()\n",
        "    text = 'START_ '+ text + ' _END'\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqBYAwDxe9ST"
      },
      "outputs": [],
      "source": [
        "# clean text\n",
        "data_df = data.copy()\n",
        "data_df[\"english_sentences\"] = data_df[\"english_sentences\"] .apply(lambda x: clean_eng(x))\n",
        "data_df[\"telugu_sentences\"] = data_df[\"telugu_sentences\"] .apply(lambda x: clean_tel(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlNPs1GZfCia"
      },
      "outputs": [],
      "source": [
        "# Vocabulary of English\n",
        "all_eng_words=set()\n",
        "for eng in data_df.english_sentences:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7lUeRkUgr2i"
      },
      "outputs": [],
      "source": [
        "# Vocabulary of Telugu \n",
        "all_telugu_words=set()\n",
        "for tel in data_df.telugu_sentences:\n",
        "    for word in tel.split():\n",
        "        if word not in all_telugu_words:\n",
        "            all_telugu_words.add(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZUOTzBdg6js",
        "outputId": "69cfeb96-99ca-48ce-c0c1-71cb82c25615"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Max Length of source sequence\n",
        "lenght_list=[]\n",
        "for l in data_df.english_sentences:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_src = np.max(lenght_list)\n",
        "max_length_src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xpkNoqlg9N8",
        "outputId": "efee08a5-b42b-479a-d133-7b79f441f4b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Max Length of target sequence\n",
        "lenght_list=[]\n",
        "for l in data_df.telugu_sentences:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_tar = np.max(lenght_list)\n",
        "max_length_tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3y0gx0HhJI4",
        "outputId": "2ac65d35-daf8-410c-a3b7-e144192f6d52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2306, 3288)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_telugu_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_telugu_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_csZOsUhO9z",
        "outputId": "53e114e0-e64c-412d-f43b-86868f7cd497"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3289"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "num_decoder_tokens += 1 # For zero padding\n",
        "num_decoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRtqG0jPh0Ip"
      },
      "outputs": [],
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Smjq21kkh0vW"
      },
      "outputs": [],
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "QMkAqd7siGsf",
        "outputId": "4a5463e9-1131-4293-90ec-9dc9ce0e6915"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     english_sentences  \\\n",
              "370  such candidates can fill the form from  octobe...   \n",
              "237  five persons have been arrested in the matter ...   \n",
              "273   an exchange discount of up to  is also available   \n",
              "386  in puntland higher education is provided by th...   \n",
              "254  the season will feature  matches in a week period   \n",
              "225  pdp won two seats whereas bjp and congress bag...   \n",
              "153  nirbhay gives indian armed forces deepstrike c...   \n",
              "421  director anil ravipudis upcoming film sarileru...   \n",
              "267  the nominations were announced by actors tiffa...   \n",
              "2    the same has been confirmed in a report carrie...   \n",
              "\n",
              "                                      telugu_sentences  \n",
              "370  START_ అర్హత గల అభ్యర్థులు నవంబర్  నుంచి నవంబర...  \n",
              "237  START_ ఐదుగురిని ఈ కేసులో అరెస్టు చేసినట్లు ఆయ...  \n",
              "273              START_ వరకు ఎక్స్చేంజ్ డిస్కౌంట్ _END  \n",
              "386  START_ పుంట్లాండులో ఉన్నత విద్యను పుంట్లాండు స...  \n",
              "254  START_ సుమారు  వారాల పాటు  మ్యాచ్‌లు జరగనున్నా...  \n",
              "225  START_ అలాగే రెండుసీట్లను కాంగ్రెస్ ఒక్కో సీటు...  \n",
              "153  START_ నిర్భయ్ క్షిపణికి గాల్లోనూ భూమ్మీద నుంచ...  \n",
              "421  START_ సూపర్ స్టార్ మహేశ్ బాబు  అనిల్ రావిపూడి...  \n",
              "267  START_ నామినేష‌న్లను వెల్ల‌డించిన ఆండీ సెర్కిస...  \n",
              "2    START_ ప్రముఖ బీబీసీ నివేదిక ఇదే విషయం పేర్కొం...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14be97ad-c70c-4eed-9480-d321cfcc7cb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentences</th>\n",
              "      <th>telugu_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>such candidates can fill the form from  octobe...</td>\n",
              "      <td>START_ అర్హత గల అభ్యర్థులు నవంబర్  నుంచి నవంబర...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>five persons have been arrested in the matter ...</td>\n",
              "      <td>START_ ఐదుగురిని ఈ కేసులో అరెస్టు చేసినట్లు ఆయ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>an exchange discount of up to  is also available</td>\n",
              "      <td>START_ వరకు ఎక్స్చేంజ్ డిస్కౌంట్ _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>in puntland higher education is provided by th...</td>\n",
              "      <td>START_ పుంట్లాండులో ఉన్నత విద్యను పుంట్లాండు స...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>the season will feature  matches in a week period</td>\n",
              "      <td>START_ సుమారు  వారాల పాటు  మ్యాచ్‌లు జరగనున్నా...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>pdp won two seats whereas bjp and congress bag...</td>\n",
              "      <td>START_ అలాగే రెండుసీట్లను కాంగ్రెస్ ఒక్కో సీటు...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>nirbhay gives indian armed forces deepstrike c...</td>\n",
              "      <td>START_ నిర్భయ్ క్షిపణికి గాల్లోనూ భూమ్మీద నుంచ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>director anil ravipudis upcoming film sarileru...</td>\n",
              "      <td>START_ సూపర్ స్టార్ మహేశ్ బాబు  అనిల్ రావిపూడి...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>the nominations were announced by actors tiffa...</td>\n",
              "      <td>START_ నామినేష‌న్లను వెల్ల‌డించిన ఆండీ సెర్కిస...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the same has been confirmed in a report carrie...</td>\n",
              "      <td>START_ ప్రముఖ బీబీసీ నివేదిక ఇదే విషయం పేర్కొం...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14be97ad-c70c-4eed-9480-d321cfcc7cb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14be97ad-c70c-4eed-9480-d321cfcc7cb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14be97ad-c70c-4eed-9480-d321cfcc7cb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "data_df = shuffle(data_df)\n",
        "data_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjZdOle-ieKt",
        "outputId": "6faa4f77-ff38-4da5-d57c-01edb465739a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((450,), (50,))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Train - Test Split\n",
        "X, y = data_df.english_sentences, data_df.telugu_sentences\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsacL9TeoKj9"
      },
      "outputs": [],
      "source": [
        "X_train.to_pickle(project_path+'X_train.pkl')\n",
        "X_test.to_pickle(project_path+'X_test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t-1w56tijG2"
      },
      "outputs": [],
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzZPPyVRixty"
      },
      "source": [
        "#Encoder - Decoder Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEnmQEyVi4jq"
      },
      "outputs": [],
      "source": [
        "latent_dim = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYpVC12mi9oJ"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVuRbyLEjAl_"
      },
      "outputs": [],
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkRKXUCpjE_U"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81HFNYl9jJzn"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "train_samples_steps = len(X_train) // batch_size\n",
        "val_samples_steps = len(X_test) // batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKIoYqsojOIU"
      },
      "outputs": [],
      "source": [
        "# generate train and test datra\n",
        "train_gen = generate_batch(X_train, y_train, batch_size = batch_size)\n",
        "test_gen = generate_batch(X_test, y_test, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ohcanx59jRbp"
      },
      "outputs": [],
      "source": [
        "# Defining a helper function to save the model after each epoch \n",
        "# in which the loss decreases \n",
        "filepath = project_path+'NMT_model_enc_dec.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "# Defining a helper function to reduce the learning rate each time \n",
        "# the learning plateaus \n",
        "reduce_alpha = ReduceLROnPlateau(monitor ='val_loss', factor = 0.2,patience = 1, min_lr = 0.001)\n",
        "# stop traning if there increase in loss\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "callbacks = [checkpoint, es, reduce_alpha] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kBYom6NxjVQj",
        "outputId": "7d4dcf01-5bad-4984-ff71-3b766ede5b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/3 [===================>..........] - ETA: 0s - loss: 0.5740 - acc: 0.0209"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-51f873eb455e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_samples_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_samples_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model/embedding/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-35-51f873eb455e>\", line 2, in <module>\n      model.fit_generator(generator = train_gen,steps_per_epoch = train_samples_steps,epochs=epochs,validation_data = test_gen,validation_steps = val_samples_steps,callbacks = callbacks)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 2223, in fit_generator\n      initial_epoch=initial_epoch)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/embeddings.py\", line 197, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model/embedding/embedding_lookup'\nindices[32,6] = 2306 is not in [0, 2306)\n\t [[{{node model/embedding/embedding_lookup}}]] [Op:__inference_train_function_14153]"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "model.fit_generator(generator = train_gen,steps_per_epoch = train_samples_steps,epochs=epochs,validation_data = test_gen,validation_steps = val_samples_steps,callbacks = callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvAiFVXUs_NS"
      },
      "source": [
        "# Inference Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyjHXAowoTDC"
      },
      "outputs": [],
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSD5cOWvtJ8d"
      },
      "source": [
        "# Decode Sample Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd2GkUdHtIr8"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmNL810MtkTt"
      },
      "source": [
        "# Evaluation on Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbFgcS1ftW1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13863e06-b28d-4434-e622-e447523e6a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: madhu chopra also revealed that priyanka had showed her the dress before wearing it to the grammys\n",
            "Actual Telugu Translation:  ప్రియాంక వేసుకోవడానికి ముందుకు కూడా తనకు శాంపిల్ చూపించనట్టుగా మధు చోప్రా వెల్లడించింది \n",
            "Predicted Telugu Translation:  పడ్డారు తెలుగుతమిళమలయాళం సిరీస్‌లో సిరీస్‌లో నార\n",
            "\n",
            "\n",
            "Input English sentence: sanand was also a member of national river ganga basin authority during the upa tenure\n",
            "Actual Telugu Translation:  యూపీఏ హయాంలో ఏర్పాటైన నేషనల్ రివర్ గంగా బేసిన్ అథారిటీలో స్వామి సనంద్ సభ్యునిగా కూడా కొనసాగారు \n",
            "Predicted Telugu Translation:  అన్నాడు సమానం సమానం ప్రశాంత్‌ ఐటీఐ రక్షణ మెహ‌రీన్ మెహ‌\n",
            "\n",
            "\n",
            "Input English sentence: this helps to make the christian congregation attractive to others who wish to be free of conflict\n",
            "Actual Telugu Translation:  దాన్ని చూసి ఇతరులు కూడా క్రైస్తవ సంఘానికి రావడానికి ఇష్టపడతారు \n",
            "Predicted Telugu Translation:  నినాదం టైగర్ టైగర్ మోడల్ తెస్తున్నాం స్టోరేజీ నటిస్తున్\n",
            "\n",
            "\n",
            "Input English sentence: he said that the movie will be released at the end of this month\n",
            "Actual Telugu Translation:  ఈ నెలలోనే సినిమా విడుదల జరుపుకుంటుందని ఆయన తెలిపారు \n",
            "Predicted Telugu Translation:  మెహ‌రీన్ స్టోరేజీ హరిదాస్‌పూర్ చ‌ర్చ రావుకు సంబ\n",
            "\n",
            "\n",
            "Input English sentence: it is not at uncommon for a telugu film to overtake hindi films\n",
            "Actual Telugu Translation:  హాలీవుడ్‌ సినిమాలను కాపీ కొట్టడం తెలుగులో ఇది కొత్తేం కాదు \n",
            "Predicted Telugu Translation:  భారతదేశంలో వివాదాస్పద అహ్మద్‌నగర్‌ ప్రాంతాల్లో \n",
            "\n",
            "\n",
            "Input English sentence: apart from his daughter chandrasekaran has three sons\n",
            "Actual Telugu Translation:  కుమారునితో పాటు ఆయనకు ముగ్గురు కుమార్తెలు సిహెచ్ \n",
            "Predicted Telugu Translation:  ఉండాలి పార్క్ నిర్మించనున్నారు జీవితాన్ని స్టో\n",
            "\n",
            "\n",
            "Input English sentence: ed to widen probe in icici bankvideocon loan fraud case to grill chanda kochhar again\n",
            "Actual Telugu Translation:  ఐసీఐసీఐ బ్యాంక్‌ – వీడియోకాన్‌ మనీల్యాండరింగ్‌ కేసులో నిందితులను మరోసారి ఈడీ విచారించనుంది \n",
            "Predicted Telugu Translation:  అరెస్ట్ కేసులు ప్రమాదం త‌దితరులు ఎన్ని అహ్మద్‌న\n",
            "\n",
            "\n",
            "Input English sentence: the film will also be released in hindi tamil telugu and malayalam\n",
            "Actual Telugu Translation:  ఈ మూవీ తెలుగుతో పాటు త‌మిళ‌ మ‌ల‌యాళ‌ హిందీ ఇంగ్లిష్ భాష‌ల్లోనూ విడుదల కానుంది \n",
            "Predicted Telugu Translation:  మెహ‌రీన్ హరిదాస్‌పూర్ వాడుకరి నాయుడు నాయుడు మార\n",
            "\n",
            "\n",
            "Input English sentence: kumaraswamy is contesting from ramanagara and channapatnatwo adjoining constituenciesin karnataka assembly elections\n",
            "Actual Telugu Translation:  కర్ణాటక అసెంబ్లీ ఎన్నికల్లో సీఎం కుమారస్వామి రామనగర చెన్నపట్న స్థానాల నుంచి పోటీ చేసి గెలుపొందారు \n",
            "Predicted Telugu Translation:  భారతదేశంలో కెపాసిటి మైసూరు మాత్రమే మాత్రమే కాన\n",
            "\n",
            "\n",
            "Input English sentence: the congress hopes to gain substantially in the upcoming elections\n",
            "Actual Telugu Translation:  వచ్చే ఎన్నికల నాటికి ఎలాగైనా బలపడాలని కాంగ్రెస్ పార్టీ భావిస్తోంది \n",
            "Predicted Telugu Translation:  రిజర్వ్ క్యాచ్‌ను ఐటీఐ పెద్ద రిజర్వ్ ఆయన ఐటీఐ ప్రాంత\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "for k in range(10):\n",
        "    (input_seq, actual_output), _ = next(test_gen)\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "    print('Actual Telugu Translation:', y_test[k:k+1].values[0][6:-4])\n",
        "    print('Predicted Telugu Translation:', decoded_sentence[:-4])\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Machine Tranlation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}